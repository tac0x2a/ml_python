# 3章 教師なし学習

------------------------------------------------------------------------------

教師なし学習の分類

+ 教師なし変換(Unsupervised transformation): 元のデータを人や機械学習アルゴリズムがわかりやすいデータへ自動的に変換するアルゴリズム．特徴量の次元削減など．

+ クラスタリングアルゴリズム(Clustering algorithms): 似たようなデータをグループ分けするアルゴリズム．

教師なし学習は正解データ(ラベル)が与えられないため，モデルの評価が難しい．
自動システムの一部としてではなく，データサイエンティストがデータを理解するために探索的に用いる場合がある．教師あり学習の前処理としても使う．

------------------------------------------------------------------------------

## スケール変換

------------------------------------------------------------------------------

教師データで作成(適用)したスケーラを用いて，訓練データもスケールする必要がある．

スケール変換による前処理がモデルに与える影響は大きく，SVCの例だと，MinMaxScalerを通すだけでスコアが0.63から0.97まで向上した．

### StandardScaler

各特徴量が平均0, 分散1になるようにスケーリングする．
最大値最小値をある値の範囲に入れようとしない．

### RobustScaler
ここの特徴量をある値の範囲に収めようとする．
平均・分散の代わりに，中央値と四分位数を用いる．
四分位数の外にある外れ値を除去してくれる．(他のスケーリングで外れ値は問題になる)

### MinMaxScaler

```py
from sklearn.preprocessing import MinMaxScaler
scaler = MinMaxScaler()

X_train_scaled = scaler.fit_transform(X_train)
# X_train_scaled = scaler.fit(X_train).transform(X_train) # 上記と同等
```

データの最小値が0，最大値が1になるよう，0から1の範囲にすべてのデータが入るようにスケールする．

### Normalizer
各データポイントの特徴ベクトルのユークリッド長が1になるように変換する．(すべてのデータポイントを半径1の超球面へ射影する)
言い換えると `x = [x1, x2, ... xn]`のとき，`sqrt( x1^2 + x2^2 + ... + xn^2 ) = 1` となるように，`x`を変換する.

特徴ベクトルの長さではなく，方向のみに関心がある場合に用いられる．

------------------------------------------------------------------------------

## Keywords

+ 四分位数: 大小関係によってデータセットを1:3または3:1に分割する値．
  + 第1四分位数: `大3:小1` に分割する値(下側)
  + 第3四分位数: `大1:小3` に分割する値(上側)

+ 外れ値(outliner):
+ 正規化: データ等々を一定のルール（規則）に基づいて変形すること